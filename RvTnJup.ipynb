{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Système de reconnaissance vocale pour un dialecte particulier -dialecte Tunisien-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date de début du projet: 20/02/2019\n",
    "#Durée estimée (arbitrairement/ non définitive): 1 an >> Date de fin: 20/02/2020\n",
    "#Auteur: Hela Menzli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaissance Vocale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Etat de l'art:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Glass, exosquelette, identification biométrique, commande vocale… ces dernières années ont vu naître pléthores de technologies dont la vocation première est de réparer, voire d’améliorer la condition de l’homme. Véritable lame de fonds et sujet à de grands questionnements sociétaux, l’intégration de ces technologies à notre quotidien, tant dans la vie professionnelle que personnelle, ne date pas d’hier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historique et Evolution: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les USA sont encore une fois en première loges. C'est dans les années 40 au USA, que les premières tentatives de création d'une machine capable de comprendre le discours humain eurent lieu. Leurs principaux objectifs étaient d'interpréter les messages russes interceptés.\n",
    "\n",
    "\n",
    "Une évolution rapide qui a suivi:\n",
    "\n",
    "- 1952 : reconnaissance des 10 chiffres par un dispositif électronique câblé.\n",
    "- 1960 : utilisation des méthodes numériques.\n",
    "- 1965 : reconnaissance de phonèmes en parole continue.\n",
    "- 1968 : reconnaissance de mots isolés par des systèmes implantés sur gros ordinateurs (jusqu’à 500 mots).\n",
    "- 1970 : Leonard E. Baum met au point le modèle caché de Markov, très utilisé en reconnaissance vocale.\n",
    "- 1971 : lancement du projet ARPA aux États-Unis (15 millions de dollars) pour tester la faisabilité de la compréhension automatique de la parole continue avec des contraintes raisonnables.\n",
    "- 1972 : premier appareil commercialisé de reconnaissance de mots.\n",
    "- 1978 : commercialisation d'un système de reconnaissance à microprocesseurs sur une carte de circuits imprimés.\n",
    "- 1983 : première mondiale de commande vocale à bord d'un avion de chasse en France.\n",
    "- 1985 : commercialisation des premiers systèmes de reconnaissance de plusieurs milliers de mots.\n",
    "- 1986 : lancement du projet japonais ATR de téléphone avec traduction automatique en temps réel.\n",
    "- 1993 : Esprit project SUNDIAL.\n",
    "- 1997 : La société Dragon lance « Naturally speaking », premier logiciel de dictée vocale.\n",
    "- 2008 : Google lance une application de recherche sur Internet mettant en œuvre une fonctionnalité de reconnaissance vocale\n",
    "- 2011 : Apple propose l'application Siri sur ses téléphones.\n",
    "- 2017 : Microsoft annonce égaler les performances de reconnaissance vocale des êtres humains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en 1972 le premier système de reconnaissance vocale était capable de reconnaître une centaine de mots isolés après une phase d’apprentissage longue et fastidieuse, l’évolution vers des systèmes de traitement automatique de la voix a été par la suite très rapide, aidée par les progrès exponentiels de l’informatique.\n",
    "\n",
    "Aujourd'hui, La parole offrant un mode d’interaction particulièrement naturel et efficace, ce sont les technologies vocales qui aujourd’hui rencontrent le plus franc succès chez les professionnels, comme chez les particuliers. Elles sont aujourd’hui à peu près partout autour de nous dans notre quotidien : téléphones, véhicules, domotique, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Technologies Vocales: (Outils et Conception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le marché des technologies vocales est constitué de trois segments distincts dans les services offerts :\n",
    "\n",
    "-\tLes services de télécommunications\n",
    "-\tLe vocal embarqué (dans les terminaux ou dans les équipements industriels)\n",
    "-\tLa dictée vocale\n",
    "\n",
    "\n",
    "La reconnaissance et la synthèse vocale sont deux technologies de base de ce domaine, mises en œuvre dans la création de dialogue Hommme-Machine. La reconnaissance permet à la machine d’identifier ce que dit un interlocuteur, tandis que la synthèse vocale permet à la machine de restituer de manière vocale un message codé à partir d’une  forme écrite.\n",
    "\n",
    "Les usages des services vocaux sont déjà nombreux, ils permettent par exemple :\n",
    "\n",
    "-\td’établir une communication en prononçant simplement le nom d’une personne (annuaire)\n",
    "-\taccéder à distance à des services dont le contenu est vocal ou textuel (exemple lecture de mail)\n",
    "-\tDisposer d’un accès multi service à partir du téléphone\n",
    "-\tPallier un handicape ( mal voyance – surdité – problème de mobilité) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\tLES OUTILS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les technologies vocales permettent aujourd’hui d’améliorer l’accès à certains services existants et devront permettre à l’avenir d’en proposer de nouveaux. Plusieurs facteurs permettent le développement de ces services : d’une part l’amélioration des performances liées aux technologies de la voix ( Amélioration des performances dans les laboratoires de recherche et départements r&d des entreprises du milieu) : Meilleure fiabilité pour la reconnaissance vocale et évolution vers une voix plus naturelle (son et prosodie) pour la synthèse. D’un point de vue matériel et économique, l’augmentation de la puissance des machines et du volume de stockage profite aussi à une ‘démocratisation’ de ces technologies de pointe.\n",
    "\n",
    "\tLa reconnaissance de la parole\n",
    "\n",
    "La reconnaissance vocale est la possibilité pour une machine, un ordinateur de reconnaître des messages oraux d’un utilisateur humain. Il y a de nombreuses applications  à ce type de technologie, les plus répandues étant la commande vocale (donner un ordre qui sera compris de la machine) et la transcription écrite (dictée vocale). Le processus de reconnaissance qui est engagé dans ces deux types d’applications peut être assez complexe. Dans le cas de la dictée vocale par exemple, le système doit être capable, non seulement de retranscrire en une chaîne phonétique les sons prononcés (en tenant compte des caractéristiques propres à la voix de chacun), mais il doit également utiliser un savoir sur la langue qui doit lui permettre de lever les ambiguïtés linguistiques inhérentes au langage naturel.\n",
    "\n",
    "Les systèmes de ce type (reconnaissance vocale) sont typiquement composés de deux modules fonctionnels : \n",
    "\n",
    "-\tL’un reçoit le signal (la parole de l’usager) et l’analyse en effectuant des mesures sur ces signaux. \n",
    "\n",
    "-\tL’autre effectue le décodage en comparant l’énoncé de l’usager à des modèles de parole ou sont représentées les phrases et les prononciations.\n",
    "\n",
    "Certains systèmes sont dits multi-locuteurs (ils sont capables de reconnaître les énoncés produits par plusieurs locuteurs). D’autres ne peuvent reconnaître qu’une seule personne après un temps d’apprentissage. (c’est souvent le cas avec des logiciel grand public du type Dragon naturally speaking)\n",
    "\n",
    "De la même manière, il existe des différentiations dans les modes d’élocution : mot à  mot (mots isolés), plusieurs mots enchaînés ou encore tous les mots de la phrase.\n",
    "\n",
    "En ce qui concerne la reconnaissance vocale, les performances dépendent directement de l’environnement dans lequel le processus est opéré. L’environnement étant un contexte important dans la conception de ce type de système.\n",
    "\n",
    "\tLa synthèse de la parole\n",
    "\n",
    "Un système de synthèse vocale à partir du texte reçoit en entrée une forme textuelle et produit en sortie le signal de parole correspondant a la forme vocalisée de ce texte. La synthèse de la parole va permettre de générer automatiquement le signal correspondant à la vocalisation d’un texte écrit. Elle constitue une alternative au pré-enregistrement de données vocales pré-déterminées (scénario de dialogue enregistré). Ce type d’application peut se retrouver dans l’utilisation des nouvelles technologies telles que l’email, le téléphone portable et les services interactifs.\n",
    "\n",
    "\tLe dialogue vocal\n",
    "\n",
    "On ne peut pas parler de « technologie » du dialogue puisque ce mode de fonctionnement est un couplage des technologies de synthèse et de reconnaissance vocale\n",
    "Ce principe utilise en fait les deux technologies précédemment citées (reconnaissance et synthèse), le dialogue vocal suit  la logique utilisateur plus qu’une logique applicative, Il existe différents types d’interaction vocale possibles, dont les complexités et le coût sont croissants. Ce « mode dialogue » se découpe en trois niveaux « de difficulté » pour ce type d’exercice :\n",
    "\n",
    "###### Niveau 1 : le dialogue directif par mot clef\n",
    "\n",
    "C’est un mode où l’utilisateur ne prononce qu’un seul mot à la fois.\n",
    "\n",
    "Exemple : Automates type  Banque\n",
    "\n",
    "Machine : « pour consulter vos compte dites ‘comptes’ »\n",
    "Homme : « comptes »\n",
    "\n",
    "###### Niveau 2 : Dialogue de type ‘ouvert’\n",
    "\n",
    "Les questions sont plus ouvertes, les réponses apparaissent plus spontanées. La mise en place de ce type de système nécessite une analyse linguistique des patrons de phrases ainsi qu’une anticipation du lexique qui sera utilisé. Ce mode est toujours basé sur l’utilisation de mots clés, mais contrairement au niveau 1 plusieurs mots peuvent être prononcés à la fois.\n",
    "\n",
    "Exemple : Automate type Banque\n",
    "\n",
    "Machine : « Quel solde désirez vous consulter»\n",
    "Homme : « le solde du compte 1234 » \t\n",
    "Homme : « Je veux consulter  le solde de mon compte chèque »  \n",
    "Homme : «J’aimerais connaître le solde du compte 1234  » \n",
    "Machine : « \n",
    "\n",
    "###### Niveau 3 : dialogue en langage naturel\n",
    "\n",
    "L’utilisateur est ‘libre’ de son discours, on parle de coopération ‘homme machine’. Ce troisième niveaux demande une couverture très importante au niveau du vocabulaire comme au niveau sémantique. Même si le système est utilisé dans un domaine très particulier. L’utilisateur  parle de sa propre initiative. Ce mode permettra par exemple de traiter les surplus d’informations comme les carences ; les changements de sujet ou des parades linguistiques plus évoluées qu’en niveau 1 et 2.\n",
    "\n",
    "Exemple : Automate type banque consultation / opérations\n",
    "\n",
    "Machine : « Quelle opération voulez vous effectuer »\n",
    "Homme : « un virement »\n",
    "Machine : « oui, à partir de quel compte ? »\n",
    "…\n",
    "\n",
    "Machine : « Quelle opération voulez vous effectuer »\n",
    "Homme : « un virement de 1000 € de mon compte épargne à mon compte chèque »\n",
    "Machine : « Désolée, les virements sont plafonnés à 100 € »\n",
    "Homme : « Faites un virement de 100 € alors ! »\n",
    "…\n",
    "\n",
    "Machine : « Quelle opération voulez vous effectuer »\n",
    "Homme : « Un virement de 100 € sur mon compte chèque à partir de mon compte d’épargne »\n",
    "Machine : « Patientez, nous vérifions votre solde »\n",
    "Machine : « vous êtes autorisé à effectuer ce virement. Nous transférons 100 € de votre compte chèque 1234 vers votre compte d’épargne 4567 »\n",
    "…\n",
    "\n",
    "Machine : « Quelle opération voulez vous effectuer »\n",
    "Homme : « j’aimerai connaître le solde de mon compte dépôt »\n",
    "Machine : « Oui, de quel compte dépôt désirez vous connaître le solde, le compte 1234 ou le compte 4567 . »\n",
    "Homme : « Combien me reste t il sur mon compte 1234 ? »\n",
    "…\n",
    "\n",
    "Certains services simples vont parfaitement être satisfaits par des systèmes fonctionnant sur les types 1 et 2 tandis que d’autres plus compliqués, plus lourds seront mieux appréhendés par des automates utilisant des traitements et technologies du niveau 3. Le temps de développement et le coût de mise en place sont alors beaucoup plus élevés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "C.\tCONCEPTION: Ergonomie Linguistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’ergonomie s’intéresse avant tout aux besoins et aux comportements d’un utilisateur (des utilisateurs). Elle vise dans le cas des technologies vocales à définir chaque étape de conception d’une application : Organisation du dialogue, les erreurs, la définition du vocabulaire, les aides possibles, les commandes possibles. \n",
    "\n",
    "L’interface doit, grâce au travail d’ergonomie ( Qui s’appuie sur les sciences cognitives), être conçue pour être efficace, mais aussi agréable et facile à utiliser pour l’utilisateur final. L’ergonome doit donc étudier d’une part les contraintes imposées par le service qu’il doit mettre en place : contraintes langagières  (vocabulaire par exemple), les contraintes matérielles (liées au type de support sur lequel va être utilisée l’application) et d’autre part les contraintes imposées par l’utilisateur : quelle est la cible du service, sexe, age, accent, origine, motivation, culture … Et enfin l’ergonome doit prendre en compte les contraintes liées à la tache en elle-même (complexité, durée …)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Les Systèmes de synthese vocale:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les systèmes de synthèse vocale (restitution à partir d’une entrée texte d’une chaîne acoustique ) sont composés de deux blocs de traitements :\n",
    "\n",
    "-  d'un bloc de traitements linguistiques. Ce bloc produit une analyse du texte a vocaliser, détermine la suite phonétique correspondante   et    lui   attache    des consignes    prosodiques    destinées  à introduire une certaine \"mélodie\" lors de la synthèse (filtres prosodiques).\n",
    "- d'un bloc de traitements acoustiques. II génère le signal de synthèse en concaténant    des    segments    de    parole naturelle       préalablement       stockés, obtenus   a   partir  de   I'enregistrement d'un locuteur expert (un acteur). \n",
    "\n",
    "\n",
    "\n",
    "La problématique étant de disposer d'une base de données suffisamment riche et d'une algorithmique élaborée pour permettre de sélectionner la séquence de phonèmes la mieux adaptée pour la production du signal de parole attendu en sortie. Actuellement, la plupart des systèmes par corpus utilisent des bases de données acoustiques de très grande taille pour permettre un rendu prosodique le plus intéressant possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\tFONCTIONNEMENT GLOBAL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grossièrement, le texte à synthétiser est transformé en suite de phonèmes (unité minimale sonore) auxquels on applique un filtre prosodique.\n",
    "\n",
    "Les principales offres du marché se différencient les unes des autres par la qualité de cette prosodie restituée par la machine, c’est ce qu’on appelle « le naturel » mais aussi par le nombre et la qualité des langues couvertes par l’offre. La qualité du timbre de voix étant un critère important dans l’évaluation de ce type de système. D’un point de vue technologique ( texte/ son ), c’est du point de vue de la qualité que va se faire l’appréciation d’un système par rapport à un autre.\n",
    "\n",
    "Les premiers systèmes de synthèse vocale procédaient par concaténation des unités acoustiques  en utilisant des dictionnaires acoustiques de taille réduite (environ 5 Mo par voix) ou chaque unité (diphone) avait un seul représentant acoustique.\n",
    "\n",
    "La disponibilité récente de ressources informatiques importantes a permis l'émergence de solutions nouvelles, regroupées sous I'appellation de \"synthèse par corpus\". Dans cette approche, la base de données acoustiques ne se restreint pas a un dictionnaire de diphones mono-représentés, mais contient des unités de taille variable (diphones, triphones, syllabes, etc.) enregistrées dans différents contextes linguistiques (d’après des corpus vocaux) et prosodiques (milieu de phrase, fin de phrase, groupe interrogatif,etc.) \n",
    "\n",
    "De plus, une prise en compte de paramètres liés à la prosodie pour la sélection des unités acoustiques devrait a terme permettre de reproduire la prosodie la plus satisfaisante. Ces améliorations, qui constituent une véritable rupture, permettront de restituer un signal synthétique très proche de la parole naturelle. \n",
    "\n",
    "Synthèse par concaténation d’unités acoustiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.\tLE MARCHE:\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous I'impulsion des nouveaux usages, le marché des solutions vocales est en pleine expansion. L’an dernier, en Europe, des sociétés importantes comme British General Motors  , RATP   (serveur SIEL), SNCF 2 (RECITAL), Chronoposte   …  ont déployé des applications de Synthèse vocale.\n",
    "\n",
    "le marché des solutions s'appuyant sur des technologies vocales dites évoluées, c'est-à-dire incluant reconnaissance et/ou synthèse vocale se partage en trois postes fondamentaux :\n",
    "\n",
    "- les logiciels \" vocaux \", reconnaissance, synthèse et dialogue en langage naturel;\n",
    "-  les plates-formes vocales et les infra¬structures   techniques   matérielles   et logicielles;\n",
    "-  la conception (en elle-même) du service.\n",
    "\n",
    "-\tDonnées financières\n",
    "\n",
    "En moyenne le coût du logiciel vocal représente 15% du coût global du service hébergé sur sa plate-forme. Si le service a une vocation commerciale, l'investissement sera supérieur, le retour se faisant alors sur la vente réalisée grâce à ce media. \n",
    "\n",
    "-\tActeurs du marché (En Europe)\n",
    "\n",
    "Nuance et Speech Works se partagent la moitié de ce marché, les autres acteurs principaux étant ScanSoft  (qui a racheté très récemment Philips ), IBM, Loquendo et Telisma (issue de France Telecom R&D et qui exploite les technologies de reconnaissance vocale initialement développées par France Telecom R&D).\n",
    "\n",
    "Deux chercheuses françaises de ce domaine, Fabienne Carpentier et Emeline Hemery, estiment que I'activité générée par ces services, exprimée en revenus provenant des clients utilisateurs, passera de 600 millions de dollars en 2001 a 25 milliards en 2006.\n",
    "(L’Europe étant au 5eme rang) \n",
    "\n",
    "- Les solutions embarquées\n",
    "\n",
    "Le marché des technologies embarquées, sous I'influence de la forte croissance des mobiles, de I'équipement automobile et de l'introduction de processeurs et de mémoires dans les biens de consommation électroménagers, va progresser plus vite encore que celui des réseaux.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ressources de cette documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Technologies vocales, état de l'art et enjeux sur JDN https://www.journaldunet.com/solutions/expert/61706/technologies-vocales--etat-de-l-art-et-enjeux.shtml\n",
    "- Projet de veille de Fabienne Carpentier et Emeline Hemery: « Faire le point sur la Synthèse Vocale & technologies de la voix  dans le but de mettre en place un serveur vocal de consultation des comptes bancaires pour nos clients »\n",
    "- Wikipédia: https://fr.wikipedia.org/wiki/Reconnaissance_automatique_de_la_parole"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
